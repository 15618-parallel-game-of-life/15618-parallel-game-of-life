# -*- coding: utf-8 -*-
"""15618Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mEZAxqL4I_qVOOTlywrgMYJ-R75D16iF
"""

!apt-get update && apt-get install ffmpeg freeglut3-dev xvfb  # For visualization
!pip install "stable-baselines3[extra]>=2.0.0a4"

import os
import gymnasium
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.evaluation import evaluate_policy

environment_name = 'CartPole-v1'
env = gymnasium.make(environment_name)

episodes = 5
for episode in range(1, episodes+1):
  state = env.reset()
  done = False
  score = 0.0

  while not done:
    action = env.action_space.sample()
    n_state, reward, done, truncated, info = env.step(action)
    score += reward
  
  print('Episode:{} Score:{}'.format(episode, score))

env.close()

log_path = os.path.join('Training', 'Logs')

log_path

env = gymnasium.make(environment_name)
env = DummyVecEnv([lambda: env])
model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)

model.learn(total_timesteps=20000)

PPO_Path = os.path.join('Training', 'Saved Models', 'PPO_Model_Cartpole')

model.save(PPO_Path)

del model

model = PPO.load(PPO_Path)

evaluate_policy(model, env, n_eval_episodes=10, render=False)

episodes = 5
for episode in range(1, episodes+1):
  obs = env.reset()
  done = False
  score = 0.0

  while not done:
    action, _ = model.predict(obs)
    obs, reward, done, info = env.step(action)
    score += reward
  
  print('Episode:{} Score:{}'.format(episode, score))

env.close()

# Set up fake display; otherwise rendering will fail
import os
os.system("Xvfb :1 -screen 0 1024x768x24 &")
os.environ['DISPLAY'] = ':1'

import base64
from pathlib import Path

from IPython import display as ipythondisplay


def show_videos(video_path="", prefix=""):
    """
    Taken from https://github.com/eleurent/highway-env

    :param video_path: (str) Path to the folder containing videos
    :param prefix: (str) Filter the video, showing only the only starting with this prefix
    """
    html = []
    for mp4 in Path(video_path).glob("{}*.mp4".format(prefix)):
        video_b64 = base64.b64encode(mp4.read_bytes())
        html.append(
            """<video alt="{}" autoplay 
                    loop controls style="height: 400px;">
                    <source src="data:video/mp4;base64,{}" type="video/mp4" />
                </video>""".format(
                mp4, video_b64.decode("ascii")
            )
        )
    ipythondisplay.display(ipythondisplay.HTML(data="<br>".join(html)))

from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv


def record_video(env_id, model, video_length=500, prefix="", video_folder="videos/"):
    """
    :param env_id: (str)
    :param model: (RL model)
    :param video_length: (int)
    :param prefix: (str)
    :param video_folder: (str)
    """
    eval_env = DummyVecEnv([lambda: gymnasium.make("CartPole-v1", render_mode="rgb_array")])
    # Start the video at step=0 and record 500 steps
    eval_env = VecVideoRecorder(
        eval_env,
        video_folder=video_folder,
        record_video_trigger=lambda step: step == 0,
        video_length=video_length,
        name_prefix=prefix,
    )

    obs = eval_env.reset()
    for _ in range(video_length):
        action, _ = model.predict(obs)
        obs, _, _, _ = eval_env.step(action)

    # Close the video recorder
    eval_env.close()

record_video("CartPole-v1", model, video_length=500, prefix="ppo-cartpole")

show_videos("videos", prefix="ppo")

training_log_path = os.path.join(log_path, 'PPO_2')

training_log_path

!tensorboard --logdir={training_log_path}

size = 10

class Network:
  def __init__(self, weights_1=None, weights_2=None, weights_3=None, biases=None):
    self.network_outputs = size * size * 0.5
    self.layer_1 = size * size
    self.layer_2 = size * size
    if weights_1 is None:
      weights_1_shape = (self.layer_1, size * size)
      self.weights_1 = np.random.normal(size=weights_1_shape)
    else:
      self.weights_1 = weights_1
    if weights_2 is None:
      weights_2_shape = (self.layer_2, self.layer_1)
      self.weights_2 = np.random.normal(size=weights_2_shape)
    else:
      self.weights_2 = weights_2
    if weights_3 is None:
      weights_3_shape = (self.network_outputs, self.layer_2)
      self.weights_3 = np.random.normal(size=weights_3_shape)
    else:
      self.weights_3 = weights_3
    if biases is None:
      self.biases = np.random.normal(size=(self.network_outputs))
    else:
      self.biases = biases

  def clone(self):
    return Network(np.copy(self.weights_1), np.copy(self.weights_2), np.copy(self.weights_3), np.copy(self.biases), self.type)

  def forward(self, observations):
    outputs_sub1 = np.matmul(self.weights_1, observations)
    outputs_sub2 = np.matmul(self.weights_2, outputs_sub1)
    outputs = np.add(np.matmul(self.weights_3, outputs_sub2), self.biases)
    return outputs

  def copy_and_mutate(self, network, mr=0.1):
    self.weights_1 = np.add(
        network.weights_1, np.random.normal(size=self.weights_1.shape) * mr)
    self.weights_2 = np.add(
        network.weights_2, np.random.normal(size=self.weights_2.shape) * mr)
    self.weights_3 = np.add(
        network.weights_3, np.random.normal(size=self.weights_3.shape) * mr)
    self.biases = np.add(
        network.biases, np.random.normal(size=self.biases.shape) * mr)

  def copy(self, network):
    self.weights_1 = network.weights_1
    self.weights_2 = network.weights_2
    self.weights_3 = network.weights_3
    self.biases = network.biases

from google.colab import files